{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文件夹中所有的文件\n",
    "feat_dir = \"/work_f/mic_dataset/feat_label/mic_dev_norm\"\n",
    "label_dir = \"/work_f/mic_dataset/feat_label/mic_dev_label\"\n",
    "feat_filename = os.listdir(feat_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = []\n",
    "val_file = []\n",
    "\n",
    "for i in feat_filename:\n",
    "    if i[4] == '1':\n",
    "        val_file.append(i)\n",
    "\n",
    "for i in feat_filename:\n",
    "    if i[4] == '3':\n",
    "        train_file.append(i)\n",
    "    elif i[4] == '4':\n",
    "        train_file.append(i)\n",
    "    elif i[4] == '5':\n",
    "        train_file.append(i)\n",
    "    elif i[4] == '6':\n",
    "        train_file.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练数据\n",
    "train_feat = []\n",
    "train_label = []\n",
    "\n",
    "npy_files = [os.path.join(feat_dir, f) for f in train_file if f.endswith('.npy')]\n",
    "for file_path in npy_files:\n",
    "    for i in np.load(file_path):\n",
    "        train_feat.append(i)\n",
    "\n",
    "npy_files = [os.path.join(label_dir, f) for f in train_file if f.endswith('.npy')]\n",
    "for file_path in npy_files:\n",
    "    for i in np.load(file_path):\n",
    "        train_label.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取验证数据\n",
    "val_feat = []\n",
    "val_label = []\n",
    "\n",
    "npy_files = [os.path.join(feat_dir, f) for f in val_file if f.endswith('.npy')]\n",
    "for file_path in npy_files:\n",
    "    for i in np.load(file_path):\n",
    "        val_feat.append(i)\n",
    "\n",
    "npy_files = [os.path.join(label_dir, f) for f in val_file if f.endswith('.npy')]\n",
    "for file_path in npy_files:\n",
    "    for i in np.load(file_path):\n",
    "        val_label.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_feat shape: (1200000, 64, 10)\n",
      "train_label shape: (240000, 56)\n",
      "val_feat shape: (300000, 64, 10)\n",
      "val_label shape: (60000, 56)\n",
      "train_feat shape: (4000, 300, 64, 10)\n",
      "train_label shape: (4000, 60, 14) (4000, 60, 42)\n",
      "val_feat shape: (1000, 300, 64, 10)\n",
      "val_label shape: (1000, 60, 14) (1000, 60, 42)\n"
     ]
    }
   ],
   "source": [
    "# 处理处理形状\n",
    "train_feat = np.array(train_feat)\n",
    "train_label = np.array(train_label)\n",
    "val_feat = np.array(val_feat)\n",
    "val_label = np.array(val_label)\n",
    "\n",
    "train_feat = np.reshape(train_feat, (-1, 64, 10))\n",
    "val_feat = np.reshape(val_feat, (-1, 64, 10))\n",
    "\n",
    "# 打印数组形状以验证转换\n",
    "print(\"train_feat shape:\", train_feat.shape)\n",
    "print(\"train_label shape:\", train_label.shape)\n",
    "print(\"val_feat shape:\", val_feat.shape)\n",
    "print(\"val_label shape:\", val_label.shape)\n",
    "\n",
    "def _split_in_seqs(data, _seq_len):\n",
    "    \"\"\"这段代码定义了一个名为 _split_in_seqs 的函数，\n",
    "    其主要目的是将输入的数据 data 按照指定的序列长度 _seq_len 进行切分。\n",
    "    这个过程将确保所有切分后的序列长度都是一致的。\"\"\"\n",
    "    if len(data.shape) == 1:\n",
    "        if data.shape[0] % _seq_len:\n",
    "            data = data[:-(data.shape[0] % _seq_len), :]\n",
    "        data = data.reshape((data.shape[0] // _seq_len, _seq_len, 1))\n",
    "    elif len(data.shape) == 2:\n",
    "        if data.shape[0] % _seq_len:\n",
    "            data = data[:-(data.shape[0] % _seq_len), :]\n",
    "        data = data.reshape((data.shape[0] // _seq_len, _seq_len, data.shape[1]))\n",
    "    elif len(data.shape) == 3:\n",
    "        if data.shape[0] % _seq_len:\n",
    "            data = data[:-(data.shape[0] % _seq_len), :, :]\n",
    "        data = data.reshape((data.shape[0] // _seq_len, _seq_len, data.shape[1], data.shape[2]))\n",
    "    else:\n",
    "        print('ERROR: Unknown data dimensions: {}'.format(data.shape))\n",
    "        exit()\n",
    "    return data\n",
    "\n",
    "train_feat = _split_in_seqs(train_feat, 300)\n",
    "val_feat = _split_in_seqs(val_feat, 300)\n",
    "\n",
    "train_label = _split_in_seqs(train_label, 60)\n",
    "val_label = _split_in_seqs(val_label, 60)\n",
    "\n",
    "train_label = [train_label[:, :, :14],train_label[:, :, 14:]]\n",
    "val_label = [val_label[:, :, :14],val_label[:, :, 14:]]\n",
    "\n",
    "print(\"train_feat shape:\", train_feat.shape)\n",
    "print(\"train_label shape:\", train_label[0].shape, train_label[1].shape)\n",
    "print(\"val_feat shape:\", val_feat.shape)\n",
    "print(\"val_label shape:\", val_label[0].shape, val_label[1].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"t1/train_feat.npy\", train_feat)\n",
    "np.save(\"t1/train_label0.npy\", train_label[0])\n",
    "np.save(\"t1/train_label1.npy\", train_label[1])\n",
    "\n",
    "np.save(\"t1/val_feat.npy\", val_feat)\n",
    "np.save(\"t1/val_label0.npy\", val_label[0])\n",
    "np.save(\"t1/val_label1.npy\", val_label[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
